{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from ddpm.diffusion_model import DiffusionModel\n",
    "\n",
    "import ddpm.config as _config\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from ddpm.data import CIFAR10_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_config.DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_path = './final.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DiffusionModel:\n\tMissing key(s) in state_dict: \"model.up_layers.8.attention.group_norm.weight\", \"model.up_layers.8.attention.group_norm.bias\", \"model.up_layers.8.attention.to_qkv.weight\", \"model.up_layers.8.attention.to_qkv.bias\", \"model.up_layers.8.attention.to_out.weight\", \"model.up_layers.8.attention.to_out.bias\", \"model.up_layers.9.attention.group_norm.weight\", \"model.up_layers.9.attention.group_norm.bias\", \"model.up_layers.9.attention.to_qkv.weight\", \"model.up_layers.9.attention.to_qkv.bias\", \"model.up_layers.9.attention.to_out.weight\", \"model.up_layers.9.attention.to_out.bias\", \"model.up_layers.10.attention.group_norm.weight\", \"model.up_layers.10.attention.group_norm.bias\", \"model.up_layers.10.attention.to_qkv.weight\", \"model.up_layers.10.attention.to_qkv.bias\", \"model.up_layers.10.attention.to_out.weight\", \"model.up_layers.10.attention.to_out.bias\", \"model.up_layers.15.upsample.1.weight\", \"model.up_layers.15.upsample.1.bias\", \"model.up_layers.16.norm1.weight\", \"model.up_layers.16.norm1.bias\", \"model.up_layers.16.conv1.weight\", \"model.up_layers.16.conv1.bias\", \"model.up_layers.16.norm2.weight\", \"model.up_layers.16.norm2.bias\", \"model.up_layers.16.conv2.1.weight\", \"model.up_layers.16.conv2.1.bias\", \"model.up_layers.16.res.weight\", \"model.up_layers.16.res.bias\", \"model.up_layers.16.class_bias.weight\", \"model.up_layers.16.time_bias.weight\", \"model.up_layers.16.time_bias.bias\", \"model.up_layers.17.norm1.weight\", \"model.up_layers.17.norm1.bias\", \"model.up_layers.17.conv1.weight\", \"model.up_layers.17.conv1.bias\", \"model.up_layers.17.norm2.weight\", \"model.up_layers.17.norm2.bias\", \"model.up_layers.17.conv2.1.weight\", \"model.up_layers.17.conv2.1.bias\", \"model.up_layers.17.res.weight\", \"model.up_layers.17.res.bias\", \"model.up_layers.17.class_bias.weight\", \"model.up_layers.17.time_bias.weight\", \"model.up_layers.17.time_bias.bias\", \"model.up_layers.18.norm1.weight\", \"model.up_layers.18.norm1.bias\", \"model.up_layers.18.conv1.weight\", \"model.up_layers.18.conv1.bias\", \"model.up_layers.18.norm2.weight\", \"model.up_layers.18.norm2.bias\", \"model.up_layers.18.conv2.1.weight\", \"model.up_layers.18.conv2.1.bias\", \"model.up_layers.18.res.weight\", \"model.up_layers.18.res.bias\", \"model.up_layers.18.class_bias.weight\", \"model.up_layers.18.time_bias.weight\", \"model.up_layers.18.time_bias.bias\", \"model.down_layers.11.downsample.weight\", \"model.down_layers.11.downsample.bias\", \"model.down_layers.12.norm1.weight\", \"model.down_layers.12.norm1.bias\", \"model.down_layers.12.conv1.weight\", \"model.down_layers.12.conv1.bias\", \"model.down_layers.12.norm2.weight\", \"model.down_layers.12.norm2.bias\", \"model.down_layers.12.conv2.1.weight\", \"model.down_layers.12.conv2.1.bias\", \"model.down_layers.12.res.weight\", \"model.down_layers.12.res.bias\", \"model.down_layers.12.attention.group_norm.weight\", \"model.down_layers.12.attention.group_norm.bias\", \"model.down_layers.12.attention.to_qkv.weight\", \"model.down_layers.12.attention.to_qkv.bias\", \"model.down_layers.12.attention.to_out.weight\", \"model.down_layers.12.attention.to_out.bias\", \"model.down_layers.12.class_bias.weight\", \"model.down_layers.12.time_bias.weight\", \"model.down_layers.12.time_bias.bias\", \"model.down_layers.13.norm1.weight\", \"model.down_layers.13.norm1.bias\", \"model.down_layers.13.conv1.weight\", \"model.down_layers.13.conv1.bias\", \"model.down_layers.13.norm2.weight\", \"model.down_layers.13.norm2.bias\", \"model.down_layers.13.conv2.1.weight\", \"model.down_layers.13.conv2.1.bias\", \"model.down_layers.13.attention.group_norm.weight\", \"model.down_layers.13.attention.group_norm.bias\", \"model.down_layers.13.attention.to_qkv.weight\", \"model.down_layers.13.attention.to_qkv.bias\", \"model.down_layers.13.attention.to_out.weight\", \"model.down_layers.13.attention.to_out.bias\", \"model.down_layers.13.class_bias.weight\", \"model.down_layers.13.time_bias.weight\", \"model.down_layers.13.time_bias.bias\". \n\tsize mismatch for model.up_layers.0.norm1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for model.up_layers.0.norm1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for model.up_layers.0.conv1.weight: copying a param with shape torch.Size([1024, 2048, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 4096, 3, 3]).\n\tsize mismatch for model.up_layers.0.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.conv2.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.up_layers.0.conv2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.res.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 4096, 1, 1]).\n\tsize mismatch for model.up_layers.0.res.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.attention.group_norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.attention.group_norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.attention.to_qkv.weight: copying a param with shape torch.Size([3072, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.0.attention.to_qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for model.up_layers.0.attention.to_out.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.0.attention.to_out.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.class_bias.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 2048]).\n\tsize mismatch for model.up_layers.0.time_bias.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for model.up_layers.0.time_bias.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.norm1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for model.up_layers.1.norm1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for model.up_layers.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 4096, 3, 3]).\n\tsize mismatch for model.up_layers.1.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.conv2.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.up_layers.1.conv2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.res.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 4096, 1, 1]).\n\tsize mismatch for model.up_layers.1.res.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.attention.group_norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.attention.group_norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.attention.to_qkv.weight: copying a param with shape torch.Size([3072, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.1.attention.to_qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for model.up_layers.1.attention.to_out.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.1.attention.to_out.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.class_bias.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 2048]).\n\tsize mismatch for model.up_layers.1.time_bias.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for model.up_layers.1.time_bias.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.norm1.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.2.norm1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.2.conv1.weight: copying a param with shape torch.Size([1024, 1536, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 3072, 3, 3]).\n\tsize mismatch for model.up_layers.2.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.conv2.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.up_layers.2.conv2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.res.weight: copying a param with shape torch.Size([1024, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 3072, 1, 1]).\n\tsize mismatch for model.up_layers.2.res.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.attention.group_norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.attention.group_norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.attention.to_qkv.weight: copying a param with shape torch.Size([3072, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.2.attention.to_qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for model.up_layers.2.attention.to_out.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.2.attention.to_out.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.class_bias.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 2048]).\n\tsize mismatch for model.up_layers.2.time_bias.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for model.up_layers.2.time_bias.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.3.upsample.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.up_layers.3.upsample.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.4.norm1.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.4.norm1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.4.conv1.weight: copying a param with shape torch.Size([512, 1536, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 3072, 3, 3]).\n\tsize mismatch for model.up_layers.4.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.conv2.1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for model.up_layers.4.conv2.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.res.weight: copying a param with shape torch.Size([512, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 3072, 1, 1]).\n\tsize mismatch for model.up_layers.4.res.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.attention.group_norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.attention.group_norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.attention.to_qkv.weight: copying a param with shape torch.Size([1536, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.4.attention.to_qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.4.attention.to_out.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.4.attention.to_out.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.class_bias.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([10, 1024]).\n\tsize mismatch for model.up_layers.4.time_bias.weight: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for model.up_layers.4.time_bias.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.5.norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 2048, 3, 3]).\n\tsize mismatch for model.up_layers.5.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.conv2.1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for model.up_layers.5.conv2.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.res.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.5.res.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.attention.group_norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.attention.group_norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.attention.to_qkv.weight: copying a param with shape torch.Size([1536, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.5.attention.to_qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.5.attention.to_out.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.5.attention.to_out.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.class_bias.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([10, 1024]).\n\tsize mismatch for model.up_layers.5.time_bias.weight: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for model.up_layers.5.time_bias.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.norm1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for model.up_layers.6.norm1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for model.up_layers.6.conv1.weight: copying a param with shape torch.Size([512, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1536, 3, 3]).\n\tsize mismatch for model.up_layers.6.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.conv2.1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for model.up_layers.6.conv2.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.res.weight: copying a param with shape torch.Size([512, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1536, 1, 1]).\n\tsize mismatch for model.up_layers.6.res.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.attention.group_norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.attention.group_norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.attention.to_qkv.weight: copying a param with shape torch.Size([1536, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.6.attention.to_qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.6.attention.to_out.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.6.attention.to_out.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.class_bias.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([10, 1024]).\n\tsize mismatch for model.up_layers.6.time_bias.weight: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for model.up_layers.6.time_bias.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.7.upsample.1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for model.up_layers.7.upsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.8.norm1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for model.up_layers.8.norm1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for model.up_layers.8.conv1.weight: copying a param with shape torch.Size([256, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1536, 3, 3]).\n\tsize mismatch for model.up_layers.8.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.8.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.8.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.8.conv2.1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for model.up_layers.8.conv2.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.8.res.weight: copying a param with shape torch.Size([256, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1536, 1, 1]).\n\tsize mismatch for model.up_layers.8.res.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.8.class_bias.weight: copying a param with shape torch.Size([10, 256]) from checkpoint, the shape in current model is torch.Size([10, 512]).\n\tsize mismatch for model.up_layers.8.time_bias.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for model.up_layers.8.time_bias.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.9.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.9.conv1.weight: copying a param with shape torch.Size([256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3, 3]).\n\tsize mismatch for model.up_layers.9.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.conv2.1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for model.up_layers.9.conv2.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.res.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.9.res.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.class_bias.weight: copying a param with shape torch.Size([10, 256]) from checkpoint, the shape in current model is torch.Size([10, 512]).\n\tsize mismatch for model.up_layers.9.time_bias.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for model.up_layers.9.time_bias.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for model.up_layers.10.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for model.up_layers.10.conv1.weight: copying a param with shape torch.Size([256, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 768, 3, 3]).\n\tsize mismatch for model.up_layers.10.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.conv2.1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for model.up_layers.10.conv2.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.res.weight: copying a param with shape torch.Size([256, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 768, 1, 1]).\n\tsize mismatch for model.up_layers.10.res.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.class_bias.weight: copying a param with shape torch.Size([10, 256]) from checkpoint, the shape in current model is torch.Size([10, 512]).\n\tsize mismatch for model.up_layers.10.time_bias.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for model.up_layers.10.time_bias.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.11.upsample.1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for model.up_layers.11.upsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.12.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for model.up_layers.12.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for model.up_layers.12.conv1.weight: copying a param with shape torch.Size([128, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 768, 3, 3]).\n\tsize mismatch for model.up_layers.12.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.12.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.12.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.12.conv2.1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for model.up_layers.12.conv2.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.12.res.weight: copying a param with shape torch.Size([128, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 768, 1, 1]).\n\tsize mismatch for model.up_layers.12.res.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.12.class_bias.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 256]).\n\tsize mismatch for model.up_layers.12.time_bias.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for model.up_layers.12.time_bias.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.13.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.13.conv1.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\n\tsize mismatch for model.up_layers.13.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.conv2.1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for model.up_layers.13.conv2.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.res.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for model.up_layers.13.res.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.class_bias.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 256]).\n\tsize mismatch for model.up_layers.13.time_bias.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for model.up_layers.13.time_bias.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for model.up_layers.14.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for model.up_layers.14.conv1.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 384, 3, 3]).\n\tsize mismatch for model.up_layers.14.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.conv2.1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for model.up_layers.14.conv2.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.res.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for model.up_layers.14.res.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.class_bias.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 256]).\n\tsize mismatch for model.up_layers.14.time_bias.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for model.up_layers.14.time_bias.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.mid_layers.0.norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.mid_layers.0.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.conv2.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.mid_layers.0.conv2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.attention.group_norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.attention.group_norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.attention.to_qkv.weight: copying a param with shape torch.Size([3072, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 2048, 1, 1]).\n\tsize mismatch for model.mid_layers.0.attention.to_qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for model.mid_layers.0.attention.to_out.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for model.mid_layers.0.attention.to_out.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.class_bias.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 2048]).\n\tsize mismatch for model.mid_layers.0.time_bias.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for model.mid_layers.0.time_bias.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.conv1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.mid_layers.1.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.conv2.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.mid_layers.1.conv2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.class_bias.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 2048]).\n\tsize mismatch for model.mid_layers.1.time_bias.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for model.mid_layers.1.time_bias.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m cpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(cpt_path, map_location\u001b[38;5;241m=\u001b[39mdevice, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m DiffusionModel(cpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDataParallel(model)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2577\u001b[0m             ),\n\u001b[0;32m   2578\u001b[0m         )\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2584\u001b[0m         )\n\u001b[0;32m   2585\u001b[0m     )\n\u001b[0;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DiffusionModel:\n\tMissing key(s) in state_dict: \"model.up_layers.8.attention.group_norm.weight\", \"model.up_layers.8.attention.group_norm.bias\", \"model.up_layers.8.attention.to_qkv.weight\", \"model.up_layers.8.attention.to_qkv.bias\", \"model.up_layers.8.attention.to_out.weight\", \"model.up_layers.8.attention.to_out.bias\", \"model.up_layers.9.attention.group_norm.weight\", \"model.up_layers.9.attention.group_norm.bias\", \"model.up_layers.9.attention.to_qkv.weight\", \"model.up_layers.9.attention.to_qkv.bias\", \"model.up_layers.9.attention.to_out.weight\", \"model.up_layers.9.attention.to_out.bias\", \"model.up_layers.10.attention.group_norm.weight\", \"model.up_layers.10.attention.group_norm.bias\", \"model.up_layers.10.attention.to_qkv.weight\", \"model.up_layers.10.attention.to_qkv.bias\", \"model.up_layers.10.attention.to_out.weight\", \"model.up_layers.10.attention.to_out.bias\", \"model.up_layers.15.upsample.1.weight\", \"model.up_layers.15.upsample.1.bias\", \"model.up_layers.16.norm1.weight\", \"model.up_layers.16.norm1.bias\", \"model.up_layers.16.conv1.weight\", \"model.up_layers.16.conv1.bias\", \"model.up_layers.16.norm2.weight\", \"model.up_layers.16.norm2.bias\", \"model.up_layers.16.conv2.1.weight\", \"model.up_layers.16.conv2.1.bias\", \"model.up_layers.16.res.weight\", \"model.up_layers.16.res.bias\", \"model.up_layers.16.class_bias.weight\", \"model.up_layers.16.time_bias.weight\", \"model.up_layers.16.time_bias.bias\", \"model.up_layers.17.norm1.weight\", \"model.up_layers.17.norm1.bias\", \"model.up_layers.17.conv1.weight\", \"model.up_layers.17.conv1.bias\", \"model.up_layers.17.norm2.weight\", \"model.up_layers.17.norm2.bias\", \"model.up_layers.17.conv2.1.weight\", \"model.up_layers.17.conv2.1.bias\", \"model.up_layers.17.res.weight\", \"model.up_layers.17.res.bias\", \"model.up_layers.17.class_bias.weight\", \"model.up_layers.17.time_bias.weight\", \"model.up_layers.17.time_bias.bias\", \"model.up_layers.18.norm1.weight\", \"model.up_layers.18.norm1.bias\", \"model.up_layers.18.conv1.weight\", \"model.up_layers.18.conv1.bias\", \"model.up_layers.18.norm2.weight\", \"model.up_layers.18.norm2.bias\", \"model.up_layers.18.conv2.1.weight\", \"model.up_layers.18.conv2.1.bias\", \"model.up_layers.18.res.weight\", \"model.up_layers.18.res.bias\", \"model.up_layers.18.class_bias.weight\", \"model.up_layers.18.time_bias.weight\", \"model.up_layers.18.time_bias.bias\", \"model.down_layers.11.downsample.weight\", \"model.down_layers.11.downsample.bias\", \"model.down_layers.12.norm1.weight\", \"model.down_layers.12.norm1.bias\", \"model.down_layers.12.conv1.weight\", \"model.down_layers.12.conv1.bias\", \"model.down_layers.12.norm2.weight\", \"model.down_layers.12.norm2.bias\", \"model.down_layers.12.conv2.1.weight\", \"model.down_layers.12.conv2.1.bias\", \"model.down_layers.12.res.weight\", \"model.down_layers.12.res.bias\", \"model.down_layers.12.attention.group_norm.weight\", \"model.down_layers.12.attention.group_norm.bias\", \"model.down_layers.12.attention.to_qkv.weight\", \"model.down_layers.12.attention.to_qkv.bias\", \"model.down_layers.12.attention.to_out.weight\", \"model.down_layers.12.attention.to_out.bias\", \"model.down_layers.12.class_bias.weight\", \"model.down_layers.12.time_bias.weight\", \"model.down_layers.12.time_bias.bias\", \"model.down_layers.13.norm1.weight\", \"model.down_layers.13.norm1.bias\", \"model.down_layers.13.conv1.weight\", \"model.down_layers.13.conv1.bias\", \"model.down_layers.13.norm2.weight\", \"model.down_layers.13.norm2.bias\", \"model.down_layers.13.conv2.1.weight\", \"model.down_layers.13.conv2.1.bias\", \"model.down_layers.13.attention.group_norm.weight\", \"model.down_layers.13.attention.group_norm.bias\", \"model.down_layers.13.attention.to_qkv.weight\", \"model.down_layers.13.attention.to_qkv.bias\", \"model.down_layers.13.attention.to_out.weight\", \"model.down_layers.13.attention.to_out.bias\", \"model.down_layers.13.class_bias.weight\", \"model.down_layers.13.time_bias.weight\", \"model.down_layers.13.time_bias.bias\". \n\tsize mismatch for model.up_layers.0.norm1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for model.up_layers.0.norm1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for model.up_layers.0.conv1.weight: copying a param with shape torch.Size([1024, 2048, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 4096, 3, 3]).\n\tsize mismatch for model.up_layers.0.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.conv2.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.up_layers.0.conv2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.res.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 4096, 1, 1]).\n\tsize mismatch for model.up_layers.0.res.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.attention.group_norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.attention.group_norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.attention.to_qkv.weight: copying a param with shape torch.Size([3072, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.0.attention.to_qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for model.up_layers.0.attention.to_out.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.0.attention.to_out.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.0.class_bias.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 2048]).\n\tsize mismatch for model.up_layers.0.time_bias.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for model.up_layers.0.time_bias.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.norm1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for model.up_layers.1.norm1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for model.up_layers.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 4096, 3, 3]).\n\tsize mismatch for model.up_layers.1.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.conv2.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.up_layers.1.conv2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.res.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 4096, 1, 1]).\n\tsize mismatch for model.up_layers.1.res.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.attention.group_norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.attention.group_norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.attention.to_qkv.weight: copying a param with shape torch.Size([3072, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.1.attention.to_qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for model.up_layers.1.attention.to_out.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.1.attention.to_out.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.1.class_bias.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 2048]).\n\tsize mismatch for model.up_layers.1.time_bias.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for model.up_layers.1.time_bias.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.norm1.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.2.norm1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.2.conv1.weight: copying a param with shape torch.Size([1024, 1536, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 3072, 3, 3]).\n\tsize mismatch for model.up_layers.2.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.conv2.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.up_layers.2.conv2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.res.weight: copying a param with shape torch.Size([1024, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 3072, 1, 1]).\n\tsize mismatch for model.up_layers.2.res.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.attention.group_norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.attention.group_norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.attention.to_qkv.weight: copying a param with shape torch.Size([3072, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.2.attention.to_qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for model.up_layers.2.attention.to_out.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.2.attention.to_out.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.2.class_bias.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 2048]).\n\tsize mismatch for model.up_layers.2.time_bias.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for model.up_layers.2.time_bias.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.3.upsample.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.up_layers.3.upsample.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.4.norm1.weight: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.4.norm1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.4.conv1.weight: copying a param with shape torch.Size([512, 1536, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 3072, 3, 3]).\n\tsize mismatch for model.up_layers.4.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.conv2.1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for model.up_layers.4.conv2.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.res.weight: copying a param with shape torch.Size([512, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 3072, 1, 1]).\n\tsize mismatch for model.up_layers.4.res.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.attention.group_norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.attention.group_norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.attention.to_qkv.weight: copying a param with shape torch.Size([1536, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.4.attention.to_qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.4.attention.to_out.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.4.attention.to_out.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.4.class_bias.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([10, 1024]).\n\tsize mismatch for model.up_layers.4.time_bias.weight: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for model.up_layers.4.time_bias.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.5.norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.up_layers.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 2048, 3, 3]).\n\tsize mismatch for model.up_layers.5.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.conv2.1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for model.up_layers.5.conv2.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.res.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 2048, 1, 1]).\n\tsize mismatch for model.up_layers.5.res.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.attention.group_norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.attention.group_norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.attention.to_qkv.weight: copying a param with shape torch.Size([1536, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.5.attention.to_qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.5.attention.to_out.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.5.attention.to_out.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.5.class_bias.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([10, 1024]).\n\tsize mismatch for model.up_layers.5.time_bias.weight: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for model.up_layers.5.time_bias.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.norm1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for model.up_layers.6.norm1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for model.up_layers.6.conv1.weight: copying a param with shape torch.Size([512, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1536, 3, 3]).\n\tsize mismatch for model.up_layers.6.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.conv2.1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for model.up_layers.6.conv2.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.res.weight: copying a param with shape torch.Size([512, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1536, 1, 1]).\n\tsize mismatch for model.up_layers.6.res.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.attention.group_norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.attention.group_norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.attention.to_qkv.weight: copying a param with shape torch.Size([1536, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.6.attention.to_qkv.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for model.up_layers.6.attention.to_out.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.6.attention.to_out.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.6.class_bias.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([10, 1024]).\n\tsize mismatch for model.up_layers.6.time_bias.weight: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([1024, 128]).\n\tsize mismatch for model.up_layers.6.time_bias.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.7.upsample.1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for model.up_layers.7.upsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.8.norm1.weight: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for model.up_layers.8.norm1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for model.up_layers.8.conv1.weight: copying a param with shape torch.Size([256, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1536, 3, 3]).\n\tsize mismatch for model.up_layers.8.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.8.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.8.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.8.conv2.1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for model.up_layers.8.conv2.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.8.res.weight: copying a param with shape torch.Size([256, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1536, 1, 1]).\n\tsize mismatch for model.up_layers.8.res.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.8.class_bias.weight: copying a param with shape torch.Size([10, 256]) from checkpoint, the shape in current model is torch.Size([10, 512]).\n\tsize mismatch for model.up_layers.8.time_bias.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for model.up_layers.8.time_bias.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.9.norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for model.up_layers.9.conv1.weight: copying a param with shape torch.Size([256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3, 3]).\n\tsize mismatch for model.up_layers.9.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.conv2.1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for model.up_layers.9.conv2.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.res.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for model.up_layers.9.res.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.9.class_bias.weight: copying a param with shape torch.Size([10, 256]) from checkpoint, the shape in current model is torch.Size([10, 512]).\n\tsize mismatch for model.up_layers.9.time_bias.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for model.up_layers.9.time_bias.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for model.up_layers.10.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for model.up_layers.10.conv1.weight: copying a param with shape torch.Size([256, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 768, 3, 3]).\n\tsize mismatch for model.up_layers.10.conv1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.conv2.1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for model.up_layers.10.conv2.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.res.weight: copying a param with shape torch.Size([256, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 768, 1, 1]).\n\tsize mismatch for model.up_layers.10.res.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.10.class_bias.weight: copying a param with shape torch.Size([10, 256]) from checkpoint, the shape in current model is torch.Size([10, 512]).\n\tsize mismatch for model.up_layers.10.time_bias.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for model.up_layers.10.time_bias.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.11.upsample.1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for model.up_layers.11.upsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.12.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for model.up_layers.12.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for model.up_layers.12.conv1.weight: copying a param with shape torch.Size([128, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 768, 3, 3]).\n\tsize mismatch for model.up_layers.12.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.12.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.12.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.12.conv2.1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for model.up_layers.12.conv2.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.12.res.weight: copying a param with shape torch.Size([128, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 768, 1, 1]).\n\tsize mismatch for model.up_layers.12.res.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.12.class_bias.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 256]).\n\tsize mismatch for model.up_layers.12.time_bias.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for model.up_layers.12.time_bias.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.13.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.up_layers.13.conv1.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\n\tsize mismatch for model.up_layers.13.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.conv2.1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for model.up_layers.13.conv2.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.res.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for model.up_layers.13.res.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.13.class_bias.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 256]).\n\tsize mismatch for model.up_layers.13.time_bias.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for model.up_layers.13.time_bias.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for model.up_layers.14.norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for model.up_layers.14.conv1.weight: copying a param with shape torch.Size([128, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 384, 3, 3]).\n\tsize mismatch for model.up_layers.14.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.conv2.1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for model.up_layers.14.conv2.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.res.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for model.up_layers.14.res.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.up_layers.14.class_bias.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 256]).\n\tsize mismatch for model.up_layers.14.time_bias.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for model.up_layers.14.time_bias.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for model.mid_layers.0.norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.mid_layers.0.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.conv2.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.mid_layers.0.conv2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.attention.group_norm.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.attention.group_norm.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.attention.to_qkv.weight: copying a param with shape torch.Size([3072, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 2048, 1, 1]).\n\tsize mismatch for model.mid_layers.0.attention.to_qkv.bias: copying a param with shape torch.Size([3072]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for model.mid_layers.0.attention.to_out.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for model.mid_layers.0.attention.to_out.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.0.class_bias.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 2048]).\n\tsize mismatch for model.mid_layers.0.time_bias.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for model.mid_layers.0.time_bias.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.conv1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.mid_layers.1.conv1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.conv2.1.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 3, 3]).\n\tsize mismatch for model.mid_layers.1.conv2.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for model.mid_layers.1.class_bias.weight: copying a param with shape torch.Size([10, 1024]) from checkpoint, the shape in current model is torch.Size([10, 2048]).\n\tsize mismatch for model.mid_layers.1.time_bias.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for model.mid_layers.1.time_bias.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048])."
     ]
    }
   ],
   "source": [
    "cpt = torch.load(cpt_path, map_location=device, weights_only=False)\n",
    "model = DiffusionModel(cpt['config'])\n",
    "model.load_state_dict(cpt['model'])\n",
    "model = nn.DataParallel(model).to(device)\n",
    "\n",
    "model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(10):\n",
    "    print(CIFAR10_CLASSES[label])\n",
    "    labels = torch.ones(image_num, dtype=torch.long, device=device) * label\n",
    "    samples = model.module.sample(shape=(image_num, 3, 32, 32), device=device, y=labels)\n",
    "    # Process all samples\n",
    "    processed_samples = [((sample + 1) / 2).clip(0, 1) for sample in samples]\n",
    "\n",
    "    # Create a grid with 5 images per row\n",
    "    grid = make_grid(processed_samples, nrow=5)\n",
    "\n",
    "    # Display the grid\n",
    "    plt.figure(figsize=(15, 3 * (len(processed_samples) // 5 + 1)))\n",
    "    plt.imshow(grid.permute(1, 2, 0).cpu())\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
